# ğŸš€ RAG-Demo: Retrieval-Augmented Generation Proof of Concept

This project demonstrates how to combine Large Language Models (LLMs) with vector databases (FAISS) locally (without using a cloud API) to efficiently search documents (PDFs, images, etc.) and generate responses based on them.

---

## ğŸ”§ Technologies

- ğŸ¤® LangChain
- ğŸ¤— HuggingFace Transformers
- ğŸ“š FAISS Vector Index
- ğŸ“„ PyPDFLoader
- ğŸ–¼ï¸ Tesseract-OCR / EasyOCR (for image processing)
- ğŸ¥ª OpenCV / PIL for image preprocessing

---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
```

### Additionally (for OCR usage):

- [Install Tesseract-OCR](https://github.com/tesseract-ocr/tesseract)
- Set `TESSDATA_PREFIX` and `tesseract_cmd` correctly (see `ocr_demo.py`)

---

## ğŸ“‚ Preparation

Place an example PDF or image (e.g., `MotivationLLM.pdf` or `postkarte_montmartre3.png`) into the project folder (`docs/paris` for CityTour).

---

## â–¶ï¸ Usage

```bash
python rag_demo_minimal.py
```

This runs a sample query:\
**"What experience does Rebecca have with LLMs?"**

---

## ğŸ¤ª Tests

```bash
pytest test_rag_demo.py
python -m unittest test_citytour_loading.py
```

---

## âœ¨ Update: OCR-powered Travel Storytelling Proof-of-Concept Complete

This update delivers the first complete version of the modular **CityTour Planner** prototype:

### ğŸ§¹ Components

- ğŸ“‚ **OCR Decorator Extended**: Automatically detects scanned documents (JPG, PNG) and performs fallback-based text extraction. OCR is only used when necessary (with caching & metadata tagging).

- ğŸ” **Image Preprocessing Demo**: `ocr_demo.py` demonstrates various pipelines to enhance OCR recognition (adaptive thresholds, CLAHE, upscaling, etc.).

- ğŸ¤  **LLM-Based Narration**: Structured or narrative summaries are generated using `Summary_Strategy` and `Storytelling_Strategy`.

- ğŸ”§ **Dummy Data & Simulation**: Initial tests use realistic sample data (PDF + OCR postcards), modularly prepared for real travel logs.

- ğŸ“† **Extensible Architecture**: Factory, Strategy, and Processor patterns allow easy extensions for more document types, languages, engines, or storytelling forms.

### ğŸ“Š OCR Evaluation Demo

Located in `demo_test_tesseract.py`, this standalone demo allows you to:

- Compare **Tesseract** vs **EasyOCR**
- Test multiple **preprocessing pipelines** (CLAHE, adaptive thresholding, upscaling)
- Visualize intermediate image stages (grayscale, denoised, thresholded, etc.)
- Experiment with different OCR configs (e.g., `--psm 6`, language selection)

Example usage:

```bash
python demo_test_tesseract.py
```

ğŸ‘‰ Input image: `docs/paris/postkarte_montmartre3.png` (sample included)\
ğŸ—ª Output: printed OCR results, plus saved intermediate images (e.g. `gray.jpg`, `resized.jpg`)

---

## âš™ï¸ Next Steps

- âœ… Test with real travel documents (e.g., scanned cards, PDFs)
- âœ… Enable full OCR pipeline with Tesseract / EasyOCR
- â†» Integrate with the interactive RAG demo
- ğŸŒ Add multilingual support (e.g., French postcards)

---

## ğŸ’¬ Feedback & Exchange

This project combines traditional software design (modularity, testability) with the creative potential of generative AI. I welcome ideas, questions, and constructive feedback! ğŸ˜Š

