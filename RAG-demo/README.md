# ğŸš€ RAG-Demo: Retrieval-Augmented Generation Proof-of-Concept

Dieses Projekt zeigt, wie man Large Language Models lokal (ohne Cloud-API) mit Vektordatenbanken (FAISS) kombiniert, um Dokumente (PDFs) effizient zu durchsuchen und darauf basierende Antworten zu generieren.

## ğŸ›  Technologien

- ğŸ§  LangChain  
- ğŸ¤— HuggingFace Transformers  
- ğŸ“š FAISS Vektorindex  
- ğŸ“„ PyPDFLoader  

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
```

## ğŸ“‚ Vorbereitung

Lege das Beispiel-PDF `MotivationLLM.pdf` in den Projektordner.

## â–¶ï¸ Nutzung

```bash
python rag_demo.py
```

Dies fÃ¼hrt eine Beispiel-Abfrage aus:
â€Welche Erfahrungen hat Rebecca mit LLMs?â€œ

## ğŸ§ª Test

```bash
pytest test_rag_demo.py
```

## ğŸ”® ZukÃ¼nftige Verbesserungen / TODOs

- CLI-Interface fÃ¼r flexible Abfragen (z.B. `python rag_demo.py --query "Deine Frage"`)  
- UnterstÃ¼tzung weiterer Dokumentformate (z.B. DOCX, TXT)  
- Verbesserte Fehlerbehandlung und Logging  
- Integration in bestehende CityTour Planner App als Modul  
- Automatisierte Tests mit verschiedenen PDFs und Queries  
- Optionaler Cloud-Support fÃ¼r grÃ¶ÃŸere Modelle  
